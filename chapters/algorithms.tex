\ctitle{Algorithms}

\paragraph{Active set methods}\index{Active set methods} Maintain estimates of the active and inactive index sets
that are updated at each step of the algorithm. Examples: the simplex method and active-set method.

\paragraph{Simplex}\index{Simplex}

\begin{codebox}
\Procname{$\proc{One Step of Simplex}()$}
\li Given $\mathcal{B}, \mathcal{N}, x_B = B^{-1}b \geq, x_N = 0;$
\li Solve $B^\top \lambda = C_B for \lambda,$
\li Compute $s_N = c_N - N^\top \lambda;$ (* pricing *)
\li \If $s_N \geq 0$ \Indentmore
\li \textbf{stop}; (* optimal point found *) \End
\li Select $q \in \mathcal{N}$ with $s_q < 0$ as the entering index;
\li Solve $Bd = A_q$ for d;
\li \If $d \leq 0$ \Indentmore
\li \textbf{stop}; (* problem is unbounded *) \End
\li Calculate $x_q^+ = \text{min}_{i | d_i > 0} (x_B)_i/d_i$, and use $p$ to
\zi denote the minimizing $i$;
\li Update $x_B^+ = x_B - dx_q^+, x_N^+ = (0, \dots, 0, x_q^+, 0, \dots, 0)^\top$;
\li Change $\mathcal{B}$ by adding $q$ and removing the basic
\zi variable corresponding to column $p$ of $B$
\end{codebox}

\paragraph{Nelder-Mead method}\index{Nelder-Mead method} A popular derivative-free optimization (DFO) method.

The centroid of the best $n$ points is denoted by
%
\begin{equation}
    \bar{x} = \sum_{i=1}^n x_i
\end{equation}

The reflection point is given by
%
\begin{equation}
    \bar{x}(t) = \bar{x} + t(x_{n+1} - \bar{x})
\end{equation}

\begin{codebox}
\Procname{$\proc{One Step of Neldear-Mead Simplex}()$}
\li Compute the reflection point $\bar{x}(-1)$
\zi and evaluate $f_{-1} = f(\bar{x}(-1))$;
\li \If $f(x_1) < f_{-1} < f(x_n) $ \Indentmore
\li (* reflected point is neither best
\zi nor worst in the new simplex *)
\zi replace $x_{n+1}$ by $\bar{x}(-1)$ and go to next iteration; \End
\li Ah, see p. 238 - 239 for the rest of the algorithm
\end{codebox}

\paragraph{MPC-based controllers}\index{MPC} MPC merges feedback control with dynamic optimization.

\begin{tabularx}{\linewidth}{p{1.3cm} X X}
	\textbf{Name} & \textbf{Optimization problem solved} & \textbf{Note}\\
	\hline
	\textbf{MPC} & Non-specified (any) & \\
	\textbf{Linear MPC} & QP with linear equality constraints and inequalities on $x$, $u$ and $\Delta u$ & \\
	\textbf{LQ} & Convex QP with only linear equality constraints & \textit{Finite-horizon:} $u_t=K_t x_t$ \textit{Infinite-horizon:} $u_t=K x_t$\\
	\textbf{LQGC} & Same as LQ & Combined with a Kalman filter\\
	\textbf{NMPC} & Non-linear optimization problems &\\
\end{tabularx}

\begin{codebox}
\Procname{$\proc{State feedback MPC procedure}()$}
\li \For $T = 0, 1, 2, \dots$ \textbf{do} \Indentmore
\li Get the current state $x_t$
\li Solve a dynamic optimization problem on
\zi the prediction horizon from $t$ to $t+N$
\zi with $x_t$ as the initial condition
\li Apply the first control move $u_t$ from
\zi the solution above \End
\end{codebox}

\noindent For an output feedback MPC procedure, line 2 in the algorithm above changes to:
%
{ \renewcommand\labelenumi{\theenumi}
\begin{enumerate}[noitemsep,nolistsep]
    \setcounter{enumi}{1}
    \item Compute an estimate of the current state $\hat{x}_t$ based on the measured data up until time $t$ 
\end{enumerate}
}

\paragraph{Methods for optimizing dynamic systems} Two important classes:
\begin{itemize}[nolistsep,noitemsep]
    \item \textit{Quasi dynamic optimization}: Optimize a dynamic system by repetitive optimization on a static model.
    \begin{itemize}[nolistsep,noitemsep]
        \item Advantages: Smaller problems and less complex formulations.
        \item Disadvantages: It cannot handle a system with significant dynamics.
    \end{itemize}
    \item \textit{Dynamic optimization}: Optimize on a dynamic model. In this case the solution will be a function of time, i.e. all decision variables will be functions of time.
\end{itemize}

